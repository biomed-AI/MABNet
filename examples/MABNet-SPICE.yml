load_model: null

# training settings
num_epochs: 3000
lr_warmup_steps: 1000
lr: 1.0e-4
lr_patience: 5
lr_min: 1.e-07
lr_factor: 0.5
weight_decay: 0.0
early_stopping_patience: 600
loss_type: MSE
loss_scale_y: 0.05
loss_scale_dy: 1.0
energy_weight: 0.5
force_weight: 0.5
gradient_clipping: 100

# dataset specific
dataset: SPICE
dataset_arg:
  version: 1.1
  max_gradient: 50.94
  subsets: ["SPICE PubChem Set 2 Single Points Dataset v1.2"]
dataset_root: /path/to/data
derivative: true
split_mode: null

# dataloader specific
reload: 0
batch_size: 2
inference_batch_size: 2
standardize: false
splits: null
train_size: 0.8
val_size: 0.1
test_size: null
num_workers: 4

# model architecture specific
model: MABNet
output_model: Scalar
prior_model: null

# architectural specific
embedding_dimension: 256
num_layers: 9
num_rbf: 32
activation: silu
rbf_type: expnorm
trainable_rbf: false
attn_activation: silu
num_heads: 8
cutoff: 5.0
cutoff_pruning: 1.6
max_z: 100
max_num_neighbors: 32
max_num_edges_save: 64
reduce_op: add
lmax: 2
vecnorm_type: none
trainable_vecnorm: false
use_padding: true
many_body: true

# other specific
ngpus: -1
num_nodes: 1
precision: 32
log_dir: /path/to/logs
task: train
seed: 1
distributed_backend: ddp
redirect: false
accelerator: gpu
test_interval: 1500
save_interval: 1
